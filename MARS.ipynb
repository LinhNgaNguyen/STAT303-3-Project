{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69dfd807",
      "metadata": {
        "id": "69dfd807"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import itertools as it\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_predict, RandomizedSearchCV\n",
        "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_regression\n",
        "import warnings\n",
        "np.warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# supress output\n",
        "%%capture\n",
        "!git clone --single-branch --branch v0.2dev https://github.com/scikit-learn-contrib/py-earth.git\n",
        "%cd py-earth\n",
        "!python setup.py install --cythonize"
      ],
      "metadata": {
        "id": "v6Y8BHMwLIJ_"
      },
      "id": "v6Y8BHMwLIJ_",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyearth import Earth"
      ],
      "metadata": {
        "id": "xfLGsJgZ9yDh"
      },
      "id": "xfLGsJgZ9yDh",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading test and train data\n",
        "train = pd.read_csv('train_clean.csv')\n",
        "test = pd.read_csv('test_clean.csv')"
      ],
      "metadata": {
        "id": "61wYv2ds-A-u"
      },
      "id": "61wYv2ds-A-u",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "Zq93D8FzZEFJ"
      },
      "id": "Zq93D8FzZEFJ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate into test and train\n",
        "y_train = train.target\n",
        "X_train = train.drop(\"target\", axis = 1)\n",
        "\n",
        "y_test = test.target\n",
        "X_test = test.drop('target', axis = 1)\n",
        "\n",
        "X_train_columns = X_train.columns\n",
        "X_test_columns = X_test.columns"
      ],
      "metadata": {
        "id": "i2zAK-Uf-Q4V"
      },
      "id": "i2zAK-Uf-Q4V",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dummy variables\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)"
      ],
      "metadata": {
        "id": "mE7mMWJXq6k8"
      },
      "id": "mE7mMWJXq6k8",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train_columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_train_columns)"
      ],
      "metadata": {
        "id": "YZmM99Lk-fhp"
      },
      "id": "YZmM99Lk-fhp",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection**"
      ],
      "metadata": {
        "id": "-JOZzsK5dP1H"
      },
      "id": "-JOZzsK5dP1H"
    },
    {
      "cell_type": "code",
      "source": [
        "# MARS model with degree 1 to help select the useful variables\n",
        "model = Earth(max_terms=1000, max_degree=1, feature_importance_type='rss')\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "cFJ4RPHKdPYA"
      },
      "id": "cFJ4RPHKdPYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance = pd.DataFrame(model.feature_importances_, columns = ['RSS'])\n",
        "predictors = pd.DataFrame(X_train.columns, columns = ['Predictors'])\n",
        "importance_df = pd.concat([predictors, importance], axis = 1).sort_values(by = 'RSS', ascending = False)\n",
        "importance_df_small = importance_df.head(37)"
      ],
      "metadata": {
        "id": "grW_btd_dJF5"
      },
      "id": "grW_btd_dJF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = importance_df_small.Predictors.tolist()"
      ],
      "metadata": {
        "id": "KyoZxshBfGg2"
      },
      "id": "KyoZxshBfGg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a new dataframe with all the predictors that are selected\n",
        "X_train_small = X_train.loc[:, selected_features]"
      ],
      "metadata": {
        "id": "v5SdhEKHdJIf"
      },
      "id": "v5SdhEKHdJIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a new dataframe with all the predictors that are selected\n",
        "X_test_small = X_test.loc[:, selected_features]\n",
        "X_test_small.shape"
      ],
      "metadata": {
        "id": "n2wcbe5rdJK9"
      },
      "id": "n2wcbe5rdJK9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Separate into test and train data**"
      ],
      "metadata": {
        "id": "CCgAjfGUuN5I"
      },
      "id": "CCgAjfGUuN5I"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test_1, y_train, y_test_1\\\n",
        "= train_test_split(X_train, y_train, test_size = 0.25, random_state = 1)"
      ],
      "metadata": {
        "id": "-PDe-GwluNDg"
      },
      "id": "-PDe-GwluNDg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test_2, y_train, y_test_2\\\n",
        "= train_test_split(X_train, y_train, test_size = 0.33, random_state = 1)"
      ],
      "metadata": {
        "id": "5C8G8Hj43Ycd"
      },
      "id": "5C8G8Hj43Ycd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test_3, y_train, y_test_3\\\n",
        "= train_test_split(X_train, y_train, test_size = 0.50, random_state = 1)"
      ],
      "metadata": {
        "id": "n22Ws8Ft3l3l"
      },
      "id": "n22Ws8Ft3l3l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding cross-validation error for trees (coarse model)\n",
        "parameters = {'max_degree': range(1,10,2)}\n",
        "\n",
        "cv = KFold(n_splits = 5,shuffle=True,random_state=1)\n",
        "\n",
        "coarse_model = GridSearchCV(Earth(max_terms = 1000), parameters, scoring = ['accuracy', 'recall'],\n",
        "                            refit = 'recall', n_jobs=-1, verbose=1, cv=cv)\n",
        "\n",
        "coarse_model.fit(X_train, y_train)\n",
        "\n",
        "# make the predictions\n",
        "y_pred = coarse_model.predict(X_test_1)\n",
        "\n",
        "print('Train accuracy : %.3f'%coarse_model.best_estimator_.score(X_train, y_train))\n",
        "print('Test accuracy : %.3f'%coarse_model.best_estimator_.score(X_test_1, y_test_1))\n",
        "print('Best accuracy Through Grid Search : %.3f'%coarse_model.best_score_)\n",
        "\n",
        "print('Best params for recall')\n",
        "print(coarse_model.best_params_)"
      ],
      "metadata": {
        "id": "DIdG-T1M-g-z"
      },
      "id": "DIdG-T1M-g-z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Earth(max_terms = 1000, max_degree = )\n",
        "\n",
        "cross_val_ypred = cross_val_predict(model, X_train, y_train, cv = 5, method = 'predict_proba')\n",
        "\n",
        "metrics = pd.DataFrame()\n",
        "i = 0\n",
        "threshold_hyperparam = np.arange(0, 1.01, 0.001)\n",
        "\n",
        "for threshold in threshold_hyperparam:\n",
        "  predicted = cross_val_ypred[:, 1] > threshold\n",
        "  predicted = predicted.astype(int)\n",
        "\n",
        "  accuracy = accuracy_score(predicted, y_train)*100\n",
        "  metrics.loc[i, 'threshold'] = threshold\n",
        "  metrics.loc[i, 'accuracy'] = accuracy\n",
        "  metrics.loc[i, 'recall'] = recall_score(y_train, predicted)*100\n",
        "  \n",
        "  i = i + 1"
      ],
      "metadata": {
        "id": "88bSV4g8AKEE"
      },
      "id": "88bSV4g8AKEE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.loc[(metrics.accuracy>=85) & (metrics.recall>85), :].sort_values(by = 'recall', ascending = False).iloc[0,:]"
      ],
      "metadata": {
        "id": "Yu-1evOlMDBs"
      },
      "id": "Yu-1evOlMDBs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Earth(max_terms = 1000, max_degree = )\n",
        "\n",
        "cross_val_ypred = cross_val_predict(model, X_train, y_train, cv = 5, method = 'predict_proba')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "p, r, thresholds = precision_recall_curve(y_train, cross_val_ypred[:,1])\n",
        "accuracy_list = []\n",
        "\n",
        "for t in thresholds:\n",
        "  y_pred_prob = model.predict_proba(X_train)[:,1]\n",
        "  y_pred = y_pred_prob > t\n",
        "  y_pred = y_pred.astype(int)\n",
        "  accuracy = (accuracy_score(y_pred, y_train))\n",
        "  accuracy_list.append(accuracy)\n",
        "\n",
        "def plot_accuracy_recall_vs_threshold(accuracy, recalls, thresholds):\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.title(\"Accuracy and Recall Scores as a function of the decision threshold\")\n",
        "  plt.plot(thresholds, accuracy_list, \"b--\", label = \"Accuracy\")\n",
        "  plt.plot(thresholds, recalls[:-1], 'g-', label = \"Recall\")\n",
        "  plt.plot(thresholds, accuracy_list, 'o', color = 'blue')\n",
        "  plt.plot(thresholds, recalls[:-1], 'o', color = 'green')\n",
        "  plt.ylabel('Score')\n",
        "  plt.xlabel('Decision Threshold')\n",
        "  plt.legend(loc='best')\n",
        "  plt.legend()\n",
        "plot_accuracy_recall_vs_threshold(accuracy_list, r, thresholds)"
      ],
      "metadata": {
        "id": "I8m5Bkp-L2N9"
      },
      "id": "I8m5Bkp-L2N9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance metrics computation for the optimum decision threshold probability\n",
        "desired_threshold = 0.080000\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_train)[:,1] \n",
        "\n",
        "# Classifying observations in the positive class (y = 1) if the predicted probability is greater\n",
        "# than the desired decision threshold probability\n",
        "y_pred = y_pred_prob > desired_threshold\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "#Computing the accuracy\n",
        "print(\"Accuracy: \",accuracy_score(y_pred, y_train)*100)  \n",
        "\n",
        "#Computing the ROC-AUC\n",
        "fpr, tpr, auc_thresholds = roc_curve(y_train, y_pred_prob)\n",
        "print(\"ROC-AUC: \",auc(fpr, tpr))# AUC of ROC\n",
        "\n",
        "#Computing the precision and recall\n",
        "print(\"Precision: \", precision_score(y_train, y_pred))\n",
        "print(\"Recall: \", recall_score(y_train, y_pred))\n",
        "\n",
        "#Confusion matrix\n",
        "cm = pd.DataFrame(confusion_matrix(y_train, y_pred), \n",
        "                  columns=['Predicted 0', 'Predicted 1'], index = ['Actual 0', 'Actual 1'])\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g');"
      ],
      "metadata": {
        "id": "_4IqNjBbL7uR"
      },
      "id": "_4IqNjBbL7uR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance metrics computation for the optimum decision threshold probability\n",
        "desired_threshold = 0.080000\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_test)[:,1] \n",
        "\n",
        "# Classifying observations in the positive class (y = 1) if the predicted probability is greater\n",
        "# than the desired decision threshold probability\n",
        "y_pred = y_pred_prob > desired_threshold\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "#Computing the accuracy\n",
        "print(\"Accuracy: \",accuracy_score(y_pred, y_test)*100)  \n",
        "\n",
        "#Computing the ROC-AUC\n",
        "fpr, tpr, auc_thresholds = roc_curve(y_test, y_pred_prob)\n",
        "print(\"ROC-AUC: \",auc(fpr, tpr))# AUC of ROC\n",
        "\n",
        "#Computing the precision and recall\n",
        "print(\"Precision: \", precision_score(y_test, y_pred))\n",
        "print(\"Recall: \", recall_score(y_test, y_pred))\n",
        "\n",
        "#Confusion matrix\n",
        "cm = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
        "                  columns=['Predicted 0', 'Predicted 1'], index = ['Actual 0', 'Actual 1'])\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g');"
      ],
      "metadata": {
        "id": "y1anZEwiMFct"
      },
      "id": "y1anZEwiMFct",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}